{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 5.1  试述将线性函数 $f(x) = ω^T X$ 用作神经元激活函数的缺陷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "什么是神经元激活函数?\n",
    "\n",
    "将输入值映射为输出值\"0\"或\"1\"。 \n",
    "- 0 对应神经元抑制\n",
    "- 1 对应神经元兴奋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "激活函数的功能是区分出激活和抑制两种状态, 那么显然线性函数是可以区分的, 且连续和光滑。 其缺陷在于\n",
    "- 变化范围太大(sigmoid能将输入挤压到0-1之间). \n",
    "- 没有引入非线性. 无论多少个线性函数, 叠加在一起, 最终还是线性函数. 也就是说多层神经网络没有了意义."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 5.2  试述使用图 5.2(b) 激活函数的神经元与对率回归的联系."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./figs/step-sigmoid.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单个神经元相当于对率回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 5.3  对于图 5.7 中的 $V_{ih}$ ， 试推导出 BP 算法中的更新公式(5.13)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 5.4  试述式 (5.6) 中学习率的取值对神经网络训练的影响."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般来说, 更大的学习率会收敛的更快, 但容易产生震荡。\n",
    "\n",
    "小的学习率容易收敛, 但需要更多的迭代次数."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 5.5 试编程实现标准BP算法和累计BP算法，在西瓜数据集3.0上分别用这两个算法训练一个单隐层网络，并进行比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import bp\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/watermelon3.0.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "y = data['label']\n",
    "y = np.array(y).reshape(1, (len(y)))\n",
    "X = data.loc[:, data.columns != 'label']\n",
    "X = np.array(X).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**标准BP算法**  运行十次取收敛轮次平均值。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss: 4.250698548940076\n",
      "epoch  0 : \n",
      "loss:  4.239059125973378\n",
      "epoch  5000 : \n",
      "loss:  0.9801840403170348\n",
      "epoch  10000 : \n",
      "loss:  0.013624568340448645\n",
      "已收敛，经过 13510 epoch\n",
      "initial loss: 4.244610281880938\n",
      "epoch  0 : \n",
      "loss:  4.2393761710914655\n",
      "epoch  5000 : \n",
      "loss:  0.03738079086978532\n",
      "epoch  10000 : \n",
      "loss:  0.008547034672977134\n",
      "已收敛，经过 11196 epoch\n",
      "initial loss: 4.2704141881352795\n",
      "epoch  0 : \n",
      "loss:  4.250628104976502\n",
      "epoch  5000 : \n",
      "loss:  0.031184820974951007\n",
      "epoch  10000 : \n",
      "loss:  0.008737411186653148\n",
      "已收敛，经过 11046 epoch\n",
      "initial loss: 4.252867034956839\n",
      "epoch  0 : \n",
      "loss:  4.241891780569643\n",
      "epoch  5000 : \n",
      "loss:  0.02469085662577539\n",
      "epoch  10000 : \n",
      "loss:  0.006134606538134247\n",
      "已收敛，经过 10037 epoch\n",
      "initial loss: 4.256710580828755\n",
      "epoch  0 : \n",
      "loss:  4.244216501415799\n",
      "epoch  5000 : \n",
      "loss:  0.023538813758742068\n",
      "epoch  10000 : \n",
      "loss:  0.0078013430162437595\n",
      "已收敛，经过 10376 epoch\n",
      "initial loss: 4.246283783501484\n",
      "epoch  0 : \n",
      "loss:  4.239227321870376\n",
      "epoch  5000 : \n",
      "loss:  0.03252521643931483\n",
      "epoch  10000 : \n",
      "loss:  0.008173394976678426\n",
      "已收敛，经过 10927 epoch\n",
      "initial loss: 4.259719596608223\n",
      "epoch  0 : \n",
      "loss:  4.245841036314808\n",
      "epoch  5000 : \n",
      "loss:  1.0039672257430836\n",
      "已收敛，经过 5335 epoch\n",
      "initial loss: 4.257775033945328\n",
      "epoch  0 : \n",
      "loss:  4.244225304840671\n",
      "epoch  5000 : \n",
      "loss:  0.0239509113021154\n",
      "epoch  10000 : \n",
      "loss:  0.007308633804234791\n",
      "已收敛，经过 10286 epoch\n",
      "initial loss: 4.251096913003808\n",
      "epoch  0 : \n",
      "loss:  4.240337727063363\n",
      "epoch  5000 : \n",
      "loss:  0.12127659303106014\n",
      "epoch  10000 : \n",
      "loss:  0.012807631459356681\n",
      "已收敛，经过 13230 epoch\n",
      "initial loss: 4.238821108653644\n",
      "epoch  0 : \n",
      "loss:  4.235353747431425\n",
      "epoch  5000 : \n",
      "loss:  1.0036272348680066\n",
      "已收敛，经过 5210 epoch\n",
      "标准BP算法收敛需 10115.3 epoch 25.497484230995177 秒\n"
     ]
    }
   ],
   "source": [
    "epoch_count = 0\n",
    "time_count = 0\n",
    "round_num = 10\n",
    "for i in range(round_num):\n",
    "    snn = bp.SimpleNeuralNetwork(X.shape[0], 5, y.shape[0])\n",
    "    st = time.time()\n",
    "    epoch_count += snn.train(X, y, eta=0.1, epoch_num=30000, batch_size=1)\n",
    "    ed = time.time()\n",
    "    time_count += ed - st\n",
    "print('标准BP算法收敛需', epoch_count / round_num, 'epoch', time_count / round_num, '秒')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**累积BP算法** 运行十次取收敛轮次平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss: 4.246401269654268\n",
      "epoch  0 : \n",
      "loss:  4.242293848565359\n",
      "epoch  5000 : \n",
      "loss:  0.02392826126833834\n",
      "已收敛，经过 9974 epoch\n",
      "initial loss: 4.252536091950381\n",
      "epoch  0 : \n",
      "loss:  4.243322625097435\n",
      "epoch  5000 : \n",
      "loss:  1.003877143954951\n",
      "已收敛，经过 5207 epoch\n",
      "initial loss: 4.247686571173056\n",
      "epoch  0 : \n",
      "loss:  4.2419764643941305\n",
      "epoch  5000 : \n",
      "loss:  0.03242800055088588\n",
      "epoch  10000 : \n",
      "loss:  0.007242592952672198\n",
      "已收敛，经过 10637 epoch\n",
      "initial loss: 4.255408945016942\n",
      "epoch  0 : \n",
      "loss:  4.246380682782556\n",
      "epoch  5000 : \n",
      "loss:  0.024188365104686034\n",
      "已收敛，经过 9951 epoch\n",
      "initial loss: 4.2589432813593096\n",
      "epoch  0 : \n",
      "loss:  4.247715698336226\n",
      "epoch  5000 : \n",
      "loss:  0.027105710234231428\n",
      "epoch  10000 : \n",
      "loss:  0.006347716996393411\n",
      "已收敛，经过 10238 epoch\n",
      "initial loss: 4.242634368742359\n",
      "epoch  0 : \n",
      "loss:  4.238951304407657\n",
      "epoch  5000 : \n",
      "loss:  1.003729902582992\n",
      "已收敛，经过 5199 epoch\n",
      "initial loss: 4.2490392933885275\n",
      "epoch  0 : \n",
      "loss:  4.24427943068534\n",
      "epoch  5000 : \n",
      "loss:  0.02551324586285322\n",
      "epoch  10000 : \n",
      "loss:  0.006949690959200835\n",
      "已收敛，经过 10319 epoch\n",
      "initial loss: 4.25058351055146\n",
      "epoch  0 : \n",
      "loss:  4.243294479878141\n",
      "epoch  5000 : \n",
      "loss:  0.02553330025885703\n",
      "epoch  10000 : \n",
      "loss:  0.006314903406826968\n",
      "已收敛，经过 10093 epoch\n",
      "initial loss: 4.25915506628321\n",
      "epoch  0 : \n",
      "loss:  4.247902204808706\n",
      "epoch  5000 : \n",
      "loss:  0.9975479441649211\n",
      "epoch  10000 : \n",
      "loss:  0.05288096639176395\n",
      "epoch  15000 : \n",
      "loss:  0.00823798447604478\n",
      "已收敛，经过 16352 epoch\n",
      "initial loss: 4.236697343025185\n",
      "epoch  0 : \n",
      "loss:  4.235131639113507\n",
      "epoch  5000 : \n",
      "loss:  0.022920076772978446\n",
      "epoch  10000 : \n",
      "loss:  0.007000996323824004\n",
      "已收敛，经过 10137 epoch\n",
      "累积BP算法收敛需 9810.7 epoch 2.092212748527527 秒\n"
     ]
    }
   ],
   "source": [
    "epoch_count = 0\n",
    "time_count = 0\n",
    "round_num = 10\n",
    "for i in range(round_num):\n",
    "    \n",
    "    snn = bp.SimpleNeuralNetwork(X.shape[0], 5, y.shape[0])\n",
    "    st = time.time()\n",
    "    epoch_count += snn.train(X, y, eta=0.1, epoch_num=30000, batch_size=17)\n",
    "    ed = time.time()\n",
    "    time_count += ed - st\n",
    "print('累积BP算法收敛需', epoch_count / round_num, 'epoch', time_count / round_num, '秒')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 5.6 试设计一个 BP 改进算法，能通过动态调整学习率显著提升收敛速度. 编程实现该算法，并选择两个 UCI 数据集与标准 BP 算法进行实验比较."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adagrad\n",
    "- Adadelta\n",
    "- RMSprop\n",
    "- Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 5.7 根据式 (5.18) 和 (5.19) ，试构造一个能解决异或问题的单层 RBF 神经网络."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 5.8 从网上下载或自己编程实现 SOM 网络，并观察其在西瓜数据集 3.0α 上产生的结果."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 5.9 试推导用于 Elman 网络的 BP 算法."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 5.10  从网上下载或自己辑程实现一个卷积神经网络?并在于写字符识剔数据 MNIST 上进行实验测试."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
