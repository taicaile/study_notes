{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 间隔与支持向量\n",
    "给定训练样本集 $D=\\left\\{\\left(\\boldsymbol{x}_{1}, y_{1}\\right),\\left(\\boldsymbol{x}_{2}, y_{2}\\right), \\ldots,\\left(\\boldsymbol{x}_{m}, y_{m}\\right)\\right\\}, y_{i} \\in\\{-1,+1\\}$, 分类学习任务最基本的想法就是基于训练集D在样本空间中找到一个划分超平面\n",
    "![](./figs/f1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直观上看应该去找位于两类训练样本\"正中间\"的划分超平面,因为该划分超平面对训练样本局部扰动的\"容忍押性最好.\n",
    "\n",
    "在样本空间中, 划分超平面可通过如下线性方程来描述:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}+b=0\n",
    "\\end{equation}\n",
    "$$\n",
    "其中$w$为法向量, 决定了超平面的方向; b 为位移项, 决定了超平面与原点之间的距离. 显然, 划分超平面可被法向量w和位移b确定。 样本空间中任意点x到超平面的距离可写为:\n",
    "\n",
    "$$\n",
    "r=\\frac{\\left|\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}+b\\right|}{\\|\\boldsymbol{w}\\|}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{array}{ll}{\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}_{i}+b \\geqslant+1,} & {y_{i}=+1} \\\\ {\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}_{i}+b \\leqslant-1,} & {y_{i}=-1}\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "距离超平面最近的这几个训练样本点使上式的等号成立, 他们被称为支持向量, 两个异类支持向量到超平面的距离之和为\n",
    "\n",
    "$$\n",
    "\\gamma=\\frac{2}{\\|\\boldsymbol{w}\\|}\n",
    "$$\n",
    "\n",
    "![](./figs/f2.jpg)\n",
    "\n",
    "它被称为 \"间隔\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欲找到具有最大间隔的划分超平面, 也就是要找到满足上式的约束的参数w和b, 使得$\\gamma$最大, 即\n",
    "$$\n",
    "\\begin{array}{l}{\\max _{\\boldsymbol{w}, b} \\frac{2}{\\|\\boldsymbol{w}\\|}} \\\\ {\\text { s.t. } y_{i}\\left(\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}_{i}+b\\right) \\geqslant 1, \\quad i=1,2, \\ldots, m}\\end{array}\n",
    "$$\n",
    "$$\\Downarrow$$\n",
    "$$\n",
    "\\begin{array}{l}{\\min _{\\boldsymbol{w}, b} \\frac{1}{2}\\|\\boldsymbol{w}\\|^{2}} \\\\ {\\text { s.t. } y_{i}\\left(\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}_{i}+b\\right) \\geqslant 1, \\quad i=1,2, \\ldots, m}\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对偶问题\n",
    "使用拉格朗日乘子法可得到其\"对偶问题\". 具体来说, 对每条约束添加拉格朗日乘子 $\\alpha_{i} \\geqslant 0$, 则该问题的拉格朗日函数可写为\n",
    "$$\n",
    "L(\\boldsymbol{w}, b, \\boldsymbol{\\alpha})=\\frac{1}{2}\\|\\boldsymbol{w}\\|^{2}+\\sum_{i=1}^{m} \\alpha_{i}\\left(1-y_{i}\\left(\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}_{i}+b\\right)\\right)\n",
    "$$\n",
    "其中\n",
    "$\\boldsymbol{\\alpha}=\\left(\\alpha_{1} ; \\alpha_{2} ; \\ldots ; \\alpha_{m}\\right)$. 令$L(\\boldsymbol{w}, b, \\boldsymbol{\\alpha})$ 对 w和b求偏导为零可得\n",
    "$$\n",
    "\\begin{aligned} \\boldsymbol{w} &=\\sum_{i=1}^{m} \\alpha_{i} y_{i} \\boldsymbol{x}_{i} \\\\ 0 &=\\sum_{i=1}^{m} \\alpha_{i} y_{i} \\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将 $L(\\boldsymbol{w}, b, \\boldsymbol{\\alpha})$ 中的w和b消去, 可得到对偶问题\n",
    "$$\n",
    "\\max _{\\alpha} \\sum_{i=1}^{m} \\alpha_{i}-\\frac{1}{2} \\sum_{i=1}^{m} \\sum_{j=1}^{m} \\alpha_{i} \\alpha_{j} y_{i} y_{j} \\boldsymbol{x}_{i}^{\\mathrm{T}} \\boldsymbol{x}_{j}\n",
    "$$\n",
    "$$\n",
    "\\begin{array}{c}{\\text { s.t. } \\sum_{i=1}^{m} \\alpha_{i} y_{i}=0} \\\\ {\\alpha_{i} \\geqslant 0, \\quad i=1,2, \\ldots, m}\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解出$\\alpha$后, 求出w与b即可得到模型\n",
    "$$\n",
    "\\begin{aligned} f(\\boldsymbol{x}) &=\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}+b \\\\ &=\\sum_{i=1}^{m} \\alpha_{i} y_{i} \\boldsymbol{x}_{i}^{\\mathrm{T}} \\boldsymbol{x}+b \\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从对偶问题解出的$\\alpha_i$是式中的拉格朗日乘子, 它恰对应这训练样本$\\left(\\boldsymbol{x}_{i}, y_{i}\\right)$. 注意到上式有不等式约束, 因此上式需满足KKT(Karush-Kuhn-Tucker)条件, 即要求\n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{array}{l}{\\alpha_{i} \\geqslant 0} \\\\ {y_{i} f\\left(\\boldsymbol{x}_{i}\\right)-1 \\geqslant 0} \\\\ {\\alpha_{i}\\left(y_{i} f\\left(\\boldsymbol{x}_{i}\\right)-1\\right)=0}\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "于是, 对任意训练样本$(x_i,j_i)$, 总有$\\alpha_{i}=0$ 或 $y_{i} f\\left(\\boldsymbol{x}_{i}\\right)=1$. 若$\\alpha_{i}=0$, 则该样本不是支持向量, 不会对f(x)有任何影响; 若 $\\alpha_{i}>0$ , 则必有$y_{i} f\\left(\\boldsymbol{x}_{i}\\right)=1$, 所对应的样本点位于最大间隔边界上, 是一个支持向量。\n",
    "\n",
    "这也显示出支持向量机的一个重要性质: 训练完成后, 大部分的训练样本都不需要保留, 最终模型仅与支持向量有关.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 核函数\n",
    "如果原始的空间是有限维, 即属性数有限, 那么一定存在一个高维特征空间使样本可分.\n",
    "$$\n",
    "f(\\boldsymbol{x})=\\boldsymbol{w}^{\\mathrm{T}} \\phi(\\boldsymbol{x})+b\n",
    "$$\n",
    "- $\\phi(\\boldsymbol{x})$ 为映射后的特征向量\n",
    "- w 和 b 是模型参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 软间隔与正则化\n",
    "允许支持向量机在一些样本上出错, 为此要引入软间隔的概念\n",
    "![软间隔](./figs/f3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要求所有样本都必须划分正确, 这称为硬间隔, 而软间隔则是允许某些样本都必须划分正确。 而软间隔则是允许某些样本不满足下列约束\n",
    "$$\n",
    "y_{i}\\left(\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}_{i}+b\\right) \\geqslant 1\n",
    "$$\n",
    "当然, 在最大化间隔的同时, 不满足约束的样本应尽可能少. 于是,优化目标可写为:\n",
    "$$\n",
    "\\min _{\\boldsymbol{w}, b} \\frac{1}{2}\\|\\boldsymbol{w}\\|^{2}+C \\sum_{i=1}^{m} \\ell_{0 / 1}\\left(y_{i}\\left(\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}_{i}+b\\right)-1\\right)\n",
    "$$\n",
    "- 其中C>0是一个常数，$\\ell_{0 / 1}$ 是 \"0/1损失函数\"\n",
    "$$\n",
    "\\ell_{0 / 1}(z)=\\left\\{\\begin{array}{ll}{1,} & {\\text { if } z<0} \\\\ {0,} & {\\text { otherwise }}\\end{array}\\right.\n",
    "$$\n",
    "- 当C为无穷大时,迫使所有样本均满足约束\n",
    "- 当C取有限值时,上式允许一些样本不满足约束\n",
    "\n",
    "#### 替代损失\n",
    "- hinge 损失: $\\ell_{\\text {hinge}}(z)=\\max (0,1-z)$\n",
    "- 指数损失： $\\ell_{\\exp }(z)=\\exp (-z)$\n",
    "- 对率损失： $\\ell_{\\log }(z)=\\log (1+\\exp (-z))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若白用hinge损失, 则\n",
    "\n",
    "$$\n",
    "\\min _{\\boldsymbol{w}, b} \\frac{1}{2}\\|\\boldsymbol{w}\\|^{2}+C \\sum_{i=1}^{m} \\max \\left(0,1-y_{i}\\left(\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}_{i}+b\\right)\\right)\n",
    "$$\n",
    "\n",
    "引入\"松弛变量\"(slack variables) $\\xi_{i} \\geqslant 0$\n",
    "$$\n",
    "\\min _{\\boldsymbol{w}, b, \\xi_{i}} \\frac{1}{2}\\|\\boldsymbol{w}\\|^{2}+C \\sum_{i=1}^{m} \\xi_{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
