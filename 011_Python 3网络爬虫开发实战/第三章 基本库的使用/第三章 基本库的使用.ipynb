{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'http.client.HTTPResponse'>\n",
      "<!doctype html>\n",
      "<!--[if lt IE 7]>   <html class=\"no-js ie6 lt-ie7 lt-ie8 lt-ie9\">   <![endif]-->\n",
      "<!--[if IE 7]>      <html class=\"no-js ie7 lt-ie8 lt-ie9\">          <![endif]-->\n",
      "<!--[if IE 8]>      <html class=\"no-js ie8 lt-ie9\">                 <![endif]-->\n",
      "<!--[if gt IE 8]><!--><html class=\"no-js\" lang=\"en\" dir=\"ltr\">  <!--<![endif]-->\n",
      "\n",
      "<head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "\n",
      "    <link rel=\"prefetch\" href=\"//ajax.googleapis.com/ajax/libs/jqu\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "response = urllib.request.urlopen('https://www.python.org')\n",
    "print(type(response))\n",
    "# 注意 response是一个类类型的对象，包含 read(), readinto(), 等.\n",
    "print(response.read().decode('utf-8')[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[('Server', 'nginx'), ('Content-Type', 'text/html; charset=utf-8'), ('X-Frame-Options', 'DENY'), ('Via', '1.1 vegur'), ('Via', '1.1 varnish'), ('Content-Length', '48360'), ('Accept-Ranges', 'bytes'), ('Date', 'Thu, 25 Jul 2019 16:46:21 GMT'), ('Via', '1.1 varnish'), ('Age', '1640'), ('Connection', 'close'), ('X-Served-By', 'cache-iad2141-IAD, cache-sin18027-SIN'), ('X-Cache', 'HIT, HIT'), ('X-Cache-Hits', '3, 15'), ('X-Timer', 'S1564073181.336745,VS0,VE0'), ('Vary', 'Cookie'), ('Strict-Transport-Security', 'max-age=63072000; includeSubDomains')]\n",
      "nginx\n"
     ]
    }
   ],
   "source": [
    "response = urllib.request.urlopen('https://www.python.org')\n",
    "print(response.status)\n",
    "print(response.getheaders())\n",
    "print(response.getheader('Server'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function urlopen in module urllib.request:\n",
      "\n",
      "urlopen(url, data=None, timeout=<object object at 0x000001997FA4D5B0>, *, cafile=None, capath=None, cadefault=False, context=None)\n",
      "    Open the URL url, which can be either a string or a Request object.\n",
      "    \n",
      "    *data* must be an object specifying additional data to be sent to\n",
      "    the server, or None if no such data is needed.  See Request for\n",
      "    details.\n",
      "    \n",
      "    urllib.request module uses HTTP/1.1 and includes a \"Connection:close\"\n",
      "    header in its HTTP requests.\n",
      "    \n",
      "    The optional *timeout* parameter specifies a timeout in seconds for\n",
      "    blocking operations like the connection attempt (if not specified, the\n",
      "    global default timeout setting will be used). This only works for HTTP,\n",
      "    HTTPS and FTP connections.\n",
      "    \n",
      "    If *context* is specified, it must be a ssl.SSLContext instance describing\n",
      "    the various SSL options. See HTTPSConnection for more details.\n",
      "    \n",
      "    The optional *cafile* and *capath* parameters specify a set of trusted CA\n",
      "    certificates for HTTPS requests. cafile should point to a single file\n",
      "    containing a bundle of CA certificates, whereas capath should point to a\n",
      "    directory of hashed certificate files. More information can be found in\n",
      "    ssl.SSLContext.load_verify_locations().\n",
      "    \n",
      "    The *cadefault* parameter is ignored.\n",
      "    \n",
      "    This function always returns an object which can work as a context\n",
      "    manager and has methods such as\n",
      "    \n",
      "    * geturl() - return the URL of the resource retrieved, commonly used to\n",
      "      determine if a redirect was followed\n",
      "    \n",
      "    * info() - return the meta-information of the page, such as headers, in the\n",
      "      form of an email.message_from_string() instance (see Quick Reference to\n",
      "      HTTP Headers)\n",
      "    \n",
      "    * getcode() - return the HTTP status code of the response.  Raises URLError\n",
      "      on errors.\n",
      "    \n",
      "    For HTTP and HTTPS URLs, this function returns a http.client.HTTPResponse\n",
      "    object slightly modified. In addition to the three new methods above, the\n",
      "    msg attribute contains the same information as the reason attribute ---\n",
      "    the reason phrase returned by the server --- instead of the response\n",
      "    headers as it is specified in the documentation for HTTPResponse.\n",
      "    \n",
      "    For FTP, file, and data URLs and requests explicitly handled by legacy\n",
      "    URLopener and FancyURLopener classes, this function returns a\n",
      "    urllib.response.addinfourl object.\n",
      "    \n",
      "    Note that None may be returned if no handler handles the request (though\n",
      "    the default installed global OpenerDirector uses UnknownHandler to ensure\n",
      "    this never happens).\n",
      "    \n",
      "    In addition, if proxy settings are detected (for example, when a *_proxy\n",
      "    environment variable like http_proxy is set), ProxyHandler is default\n",
      "    installed and makes sure the requests are handled through the proxy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# urlopen()方法可以完成最基本的简单网页的GET请求抓取。\n",
    "help(urllib.request.urlopen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data参数, 可选。 如果要添加该参数, 并且如果它是字节流编码格式的内容, 即bytes类型, 则需要通过bytes()方法转化。 另外, 如果传递了这个参数, 则它的请求方式就不再是GET方式, 而是POST方式."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\\n  \"args\": {}, \\n  \"data\": \"\", \\n  \"files\": {}, \\n  \"form\": {\\n    \"word\": \"hello\"\\n  }, \\n  \"headers\": {\\n    \"Accept-Encoding\": \"identity\", \\n    \"Content-Length\": \"10\", \\n    \"Content-Type\": \"application/x-www-form-urlencoded\", \\n    \"Host\": \"httpbin.org\", \\n    \"User-Agent\": \"Python-urllib/3.6\"\\n  }, \\n  \"json\": null, \\n  \"origin\": \"119.95.60.62, 119.95.60.62\", \\n  \"url\": \"https://httpbin.org/post\"\\n}\\n'\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse\n",
    "import urllib.request\n",
    "data = bytes(urllib.parse.urlencode({'word':'hello'}), encoding='utf8')\n",
    "response = urllib.request.urlopen('http://httpbin.org/post', data=data)\n",
    "print(response.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- timeout 参数\n",
    "timeout参数用于设置超时时间, 单位为秒, 意思就是如果请求超出了设置的这个时间, 还没有得到响应, 就会抛出异常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<urlopen error timed out>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "try:\n",
    "    response = urllib.request.urlopen('http://httpbin.org/get', timeout=0.1)\n",
    "    print(response.read())\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# 这里设置了超时时间为0.1秒, 发生超时事件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME OUT\n"
     ]
    }
   ],
   "source": [
    "# 如果一个网页长时间未响应, 就跳过它的抓取。 这可以利用try except语句来实现\n",
    "import socket\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "try:\n",
    "    response = urllib.request.urlopen('http://httpbin.org/get', timeout=0.1)\n",
    "except urllib.error.URLError as e:\n",
    "    if isinstance(e.reason, socket.timeout):\n",
    "        print('TIME OUT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<!--[if lt IE 7]>   <html class=\"no-js ie6 lt-ie7 lt-ie8 lt-ie9\">   <![endif]-->\n",
      "<!--[if IE 7]>      <html class=\"no-js ie7 lt-ie8 lt-ie9\">          <![endif]-->\n",
      "<!--[if IE 8]>      <html class=\"no-js ie8 lt-ie9\">                 <![endif]-->\n",
      "<!--[if gt IE 8]><!--><html class=\"no-js\" lang=\"en\" dir=\"ltr\">  <!--<![endif]-->\n",
      "\n",
      "<head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "\n",
      "    <link rel=\"prefetch\" href=\"//ajax.googleapis.com/ajax/libs/jqu\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "request = urllib.request.Request('https://python.org')\n",
    "response = urllib.request.urlopen(request)\n",
    "print(response.read().decode('utf-8')[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现, 我们依然用urlopen()方法发起基本的请求, 只不过这次该方法的参数不再是URL, 二十一个Request类型的对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {\n",
      "    \"name\": \"Germey\"\n",
      "  }, \n",
      "  \"headers\": {\n",
      "    \"Accept-Encoding\": \"identity\", \n",
      "    \"Content-Length\": \"11\", \n",
      "    \"Content-Type\": \"application/x-www-form-urlencoded\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"origin\": \"119.95.60.62, 119.95.60.62\", \n",
      "  \"url\": \"https://httpbin.org/post\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 传入多个参数构建请求\n",
    "from urllib import request, parse\n",
    "url = 'http://httpbin.org/post'\n",
    "headers = {\n",
    "    'user-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',\n",
    "    'Host': 'httpbin.org'\n",
    "}\n",
    "dict = {\n",
    "    'name':'Germey'\n",
    "}\n",
    "\n",
    "data = bytes(parse.urlencode(dict), encoding='utf8')\n",
    "req = request.Request(url=url, data = data, headers = headers, method='POST')\n",
    "response = request.urlopen(req)\n",
    "print(response.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察结果可以发现, 我们成功设置了data, headers 和 method。\n",
    "\n",
    "另外, headers也可以用 add_header()方法来添加:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<urllib.request.Request object at 0x0000019903EFD4E0>\n"
     ]
    }
   ],
   "source": [
    "req = request.Request(url=url, data=data, method='POST')\n",
    "req.add_header('User-Agent',\"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\")\n",
    "print(req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高级用法\n",
    "对于一些更高级的操作, 比如 Cookies处理, 代理设置等, 可以使用Handler\n",
    "\n",
    "urllib.request模块里的BaseHandler类, 它是所有其他Handler的父类\n",
    "\n",
    "另外一个比较重要的类就是OpenerDirector, 我们可以称为Opener, urlopen()这个方法, 实际上他就是urllib为我们提供的一个Opener, Openr 可以使用open()方法, 返回的类型和urlopen()一样。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 验证\n",
    "有些网站在打开时就会弹出提示框, 直接提示你输入用户名和密码, 验证成功后才能查看页面\n",
    "\n",
    "    对于这样的页面, 可以借助HTTPBasicAuthHandler就可以完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "  <head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>Dashboard - pyspider</title>\n",
      "    <!--[if lt IE 9]>\n",
      "      <script src=\"http://html5shim.googlecode.com/svn/trunk/html5.js\"></script>\n",
      "    <![endif]-->\n",
      "\n",
      "    <meta name=\"description\" content=\"pyspider dashboard\">\n",
      "    <meta name=\"author\" content=\"binux\">\n",
      "    <link href=\"//cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.1.1/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
      "    <link href=\"//cdnjs.cloudflare.com/ajax/libs/x-edita\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import HTTPPasswordMgrWithDefaultRealm, HTTPBasicAuthHandler, build_opener\n",
    "from urllib.error import URLError\n",
    "\n",
    "username = 'username'\n",
    "password = 'password'\n",
    "url = 'http://localhost:5000'\n",
    "\n",
    "p = HTTPPasswordMgrWithDefaultRealm()\n",
    "p.add_password(None, url, username, password)\n",
    "auth_handler = HTTPBasicAuthHandler(p)\n",
    "opener = build_opener(auth_handler)\n",
    "\n",
    "try:\n",
    "    result = opener.open(url)\n",
    "    html = result.read().decode('utf-8')\n",
    "    print(html[:500])\n",
    "except URLError as e:\n",
    "    print(e.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 代理\n",
    "在做爬虫的时候, 免不了要使用代理, 如果要添加代理,可以这样做:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 10061] No connection could be made because the target machine actively refused it\n"
     ]
    }
   ],
   "source": [
    "from urllib.error import URLError\n",
    "from urllib.request import ProxyHandler, build_opener\n",
    "\n",
    "proxy_handler = ProxyHandler({\n",
    "    'http':'http://127.0.0.1:9743',\n",
    "    'https':'https://127.0.0.1:9743'\n",
    "})\n",
    "opener = build_opener(proxy_handler)\n",
    "try:\n",
    "    response = opener.open('https://www.baidu.com')\n",
    "    print(response.read().decode('utf-8'))\n",
    "except URLError as e:\n",
    "    print(e.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里需要在本地搭建一个代理, 并将其运行在9743端口上。\n",
    "\n",
    "上面报错的原因是由于没有安装代理, 无法连接。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAIDUID = 3D66A92FDD4BE44C3FDFA49DFDD7687D:FG=1\n",
      "BIDUPSID = 3D66A92FDD4BE44C3FDFA49DFDD7687D\n",
      "H_PS_PSSID = 1453_21106_18559_29519_28519_29098_29568_28833_29220_26350_29072_22158\n",
      "PSTM = 1564073187\n",
      "delPer = 0\n",
      "BDSVRTM = 0\n",
      "BD_HOME = 0\n"
     ]
    }
   ],
   "source": [
    "import http.cookiejar, urllib.request\n",
    "cookie = http.cookiejar.CookieJar()\n",
    "handler = urllib.request.HTTPCookieProcessor(cookie)\n",
    "opener = urllib.request.build_opener(handler)\n",
    "# cookie 只有在与服务器连接之后才能读取\n",
    "response = opener.open('http://www.baidu.com')\n",
    "for item in cookie:\n",
    "    print(item.name + ' = '+item.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将cookies存储为文本格式\n",
    "filename = 'cookies.txt'\n",
    "cookie = http.cookiejar.MozillaCookieJar(filename)\n",
    "handler = urllib.request.HTTPCookieProcessor(cookie)\n",
    "opener = urllib.request.build_opener(handler)\n",
    "response = opener.open('http://www.baidu.com')\n",
    "cookie.save(ignore_discard=True, ignore_expires=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Netscape HTTP Cookie File\n",
      "# http://curl.haxx.se/rfc/cookie_spec.html\n",
      "# This is a generated file!  Do not edit.\n",
      "\n",
      ".baidu.com      TRUE    /       FALSE   3711556831      BAIDUID 3D66A92FDD4BE44CCADC58E49A51D138:FG=1\n",
      ".baidu.com      TRUE    /       FALSE   3711556831      BIDUPSID        3D66A92FDD4BE44CCADC58E49A51D138\n",
      ".baidu.com      TRUE    /       FALSE           H_PS_PSSID      1993_1461_21081_18559_29521_28518_29099_29568_28839_29220\n",
      ".baidu.com      TRUE    /       FALSE   3711556831      PSTM    1564073187\n",
      ".baidu.com      TRUE    /       FALSE           delPer  0\n",
      "www.baidu.com   FALSE   /       FALSE           BDSVRTM 0\n",
      "www.baidu.com   FALSE   /       FALSE           BD_HOME 0\n"
     ]
    }
   ],
   "source": [
    "!more cookies.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外, LWPCookieJar同样可以读取和保存Cookies, 但是保存的格式和MozillaCookieJar不一样, 它会保存成libwww-perl格式的Cookies文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将cookies存储为lwp格式\n",
    "filename = 'lwpcookies.txt'\n",
    "cookie = http.cookiejar.LWPCookieJar(filename)\n",
    "handler = urllib.request.HTTPCookieProcessor(cookie)\n",
    "opener = urllib.request.build_opener(handler)\n",
    "response = opener.open('http://www.baidu.com')\n",
    "cookie.save(ignore_discard=True, ignore_expires=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#LWP-Cookies-2.0\n",
      "Set-Cookie3: BAIDUID=\"3D66A92FDD4BE44C3E5A11C617521CBD:FG=1\"; path=\"/\"; domain=\".baidu.com\"; path_spec; domain_dot; expires=\"2087-08-12 20:00:31Z\"; version=0\n",
      "Set-Cookie3: BIDUPSID=3D66A92FDD4BE44C3E5A11C617521CBD; path=\"/\"; domain=\".baidu.com\"; path_spec; domain_dot; expires=\"2087-08-12 20:00:31Z\"; version=0\n",
      "Set-Cookie3: H_PS_PSSID=1431_21090_29519_28519_29099_29568_28838_29221; path=\"/\"; domain=\".baidu.com\"; path_spec; domain_dot; discard; version=0\n",
      "Set-Cookie3: PSTM=1564073187; path=\"/\"; domain=\".baidu.com\"; path_spec; domain_dot; expires=\"2087-08-12 20:00:31Z\"; version=0\n",
      "Set-Cookie3: delPer=0; path=\"/\"; domain=\".baidu.com\"; path_spec; domain_dot; discard; version=0\n",
      "Set-Cookie3: BDSVRTM=0; path=\"/\"; domain=\"www.baidu.com\"; path_spec; discard; version=0\n",
      "Set-Cookie3: BD_HOME=0; path=\"/\"; domain=\"www.baidu.com\"; path_spec; discard; version=0\n"
     ]
    }
   ],
   "source": [
    "!more lwpcookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<!--STATUS OK-->\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# 如何使用cookies\n",
    "cookie = http.cookiejar.LWPCookieJar()\n",
    "cookie.load('lwpcookies.txt', ignore_discard=True, ignore_expires=True)\n",
    "handler = urllib.request.HTTPCookieProcessor(cookie)\n",
    "opener = urllib.request.build_opener(handler)\n",
    "response = opener.open('http://www.baidu.com')\n",
    "print(response.read().decode('utf-8')[:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
